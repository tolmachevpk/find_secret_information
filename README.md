## Поиск секретной информации
Сейчас я расскажу, какие были идеи по решению этой задачи, и на какой я остановился.
### Алгоритм Кнута-Мориса-Прата
Крайне эффективный алгоритм, но появлялась проблема, что не обязательно нужное нам совпадение будет префиксом данного файла. 
Поэтому от текущего решения пришлось отказаться, хоть оно и было сильно эффективным.
### Решение с помощью Ахо-Корасика
Здесь идея была такая: предполагаем, что можем взять все наборы 4 килобайтовых подстрок данного файла и загрузить все это в суфиксный бор. Сложность у алгоритма O(n * f + H + k), где n - общая длина всех слов в словаре, f - размер алфавита (256 символов), 
H - длина текста, в котором производится поиск, k - общая длина всех совпадений, но k в нашем случае можно взять 4 * 1024, потому что искать остальные уже нет смысла, нам по условию нужно понять, есть хотя бы одно или нет. 
Пусть m - количество байт в файле, тогда построение бора будет там стоить примерно O(m^2).  
В итоге сложность примерно O(m^2 + H).
### Поиск наибольшей общей подстроки с использованием хэширования
Здесь у нас сложность получалась бы log(m) * H.
### Интуитивный вывод
Так как у нас большое количество файлов в H, то H >> m, следовательно скорее всего будет дешевле для нас взять O(m^2 + H), чем O(H * lon(m)). Но давайте подумаем еще, в среднем H должен быть 
больше m минимум в 10^6 раз, значит H ~ m * 10^6, но если мы подставим в наши соотношения эти значения и поделим друг на друга, от получим такое: </br>
(m^2 + m * 10^6) / (log(m) * m * 10^6) = (m + 10^6) / (10^6 * log(m)) </br>
Данное соотношение меньше единицы при размере m от 3 байт до 15 млн байт (~ 15 мб), учитывая, что файлов в H таких миллион, то, по верхней границе будет 15 тб, что достаточно много, поэтому предполагая, что компьютер у нас не самый вместительный, в этом случае Ахо-Корасик подойдет нам больше.
